{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Dil34lm2V1T6"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB_0dFbHdrBg"
      },
      "source": [
        "# generating training dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "CHqtsBP8du2s",
        "outputId": "1a13f25c-38c7-41b0-e978-6899fd504b84"
      },
      "outputs": [],
      "source": [
        "train_data = np.loadtxt(\"Train_Data.txt\", delimiter=',', dtype=str)\n",
        "test_data = np.loadtxt(\"Test_Data.txt\", delimiter=',', dtype=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlNQjWYg-y6F",
        "outputId": "e529c296-4853-4fd0-fd36-287780d98e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          ID x1 x2 x3 x4 x5  x6 x7 x8 x9 class\n",
            "0    1000025  5  1  1  1  2   1  3  1  1     2\n",
            "1    1002945  5  4  4  5  7  10  3  2  1     2\n",
            "2    1015425  3  1  1  1  2   2  3  1  1     2\n",
            "3    1016277  6  8  8  1  3   4  3  7  1     2\n",
            "4    1017023  4  1  1  3  2   1  3  1  1     2\n",
            "..       ... .. .. .. .. ..  .. .. .. ..   ...\n",
            "594  1315506  4  8  6  3  4  10  7  1  1     4\n",
            "595  1320141  5  1  1  1  2   1  2  1  1     2\n",
            "596  1325309  4  1  2  1  2   1  2  1  1     2\n",
            "597  1333063  5  1  3  1  2   1  3  1  1     2\n",
            "598  1333495  3  1  1  1  2   1  2  1  1     2\n",
            "\n",
            "[599 rows x 11 columns]\n",
            "         ID x1  x2  x3 x4 x5 x6  x7  x8 x9 class\n",
            "0   1334659  5   2   4  1  1  1   1   1  1     2\n",
            "1   1336798  3   1   1  1  2  1   2   1  1     2\n",
            "2   1344449  1   1   1  1  1  1   2   1  1     2\n",
            "3   1350568  4   1   1  1  2  1   2   1  1     2\n",
            "4   1352663  5   4   6  8  4  1   8  10  1     4\n",
            "..      ... ..  ..  .. .. .. ..  ..  .. ..   ...\n",
            "95   776715  3   1   1  1  3  2   1   1  1     2\n",
            "96   841769  2   1   1  1  2  1   1   1  1     2\n",
            "97   888820  5  10  10  3  7  3   8  10  2     4\n",
            "98   897471  4   8   6  4  3  4  10   6  1     4\n",
            "99   897471  4   8   8  5  4  5  10   4  1     4\n",
            "\n",
            "[100 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "column_names = ['ID', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'class']\n",
        "\n",
        "\n",
        "df_train = pd.DataFrame(train_data, columns=column_names)\n",
        "df_test = pd.DataFrame(test_data, columns=column_names)\n",
        "\n",
        "\n",
        "print(df_train)\n",
        "print(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXYIBh9jw9Hq"
      },
      "source": [
        "## Feature Selection or Manipulation\n",
        "#### + test set preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsHFLJ9oulM2",
        "outputId": "096336de-cc4c-4f15-bafd-ec81496023b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([599, 6])\n",
            "x_train shape: torch.Size([599, 6])\n",
            "y_train shape: torch.Size([599, 1])\n"
          ]
        }
      ],
      "source": [
        "df_train = df_train.replace('?', '0') \n",
        "df_test = df_test.replace('?', '0')\n",
        "\n",
        "feature_cols = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9']\n",
        "features_to_use = [ 'x2/2', 'x3', 'x4/2', 'x6', 'x8/2','x9']\n",
        "\n",
        "for col in feature_cols:\n",
        "    df_train[col] = pd.to_numeric(df_train[col], errors='coerce') \n",
        "    df_test[col] = pd.to_numeric(df_test[col], errors='coerce')\n",
        "\n",
        "df_train['class'] = pd.to_numeric(df_train['class'], errors='coerce')\n",
        "df_test['class'] = pd.to_numeric(df_test['class'], errors='coerce')\n",
        "\n",
        "\n",
        "# #Feature Modification\n",
        "df_train['x2/2'] = df_train['x2'] /2\n",
        "df_test['x2/2'] = df_test['x2']/  2\n",
        "df_train['x4/2'] = df_train['x4'] / 2\n",
        "df_test['x4/2'] = df_test['x4']/  2\n",
        "df_train['x8/2'] = df_train['x8'] /2\n",
        "df_test['x8/2'] = df_test['x8']/  2\n",
        "\n",
        "\n",
        "X = df_train[features_to_use].values.astype(np.float32) \n",
        "Xt = df_test[features_to_use].values.astype(np.float32)\n",
        "\n",
        "Y = df_train['class'].replace({4.0: 1.0, 2.0: 0.0}).values.astype(np.float32)\n",
        "Yt = df_test['class'].replace({4.0: 1.0, 2.0: 0.0}).values.astype(np.float32)\n",
        "\n",
        "#Standardize\n",
        "X_mean = X.mean(axis=0)\n",
        "X_std = X.std(axis=0)\n",
        "X_train_scaled = (X - X_mean) / X_std\n",
        "\n",
        "X_test_scaled = (Xt - X_mean) / X_std\n",
        "\n",
        "x_train = torch.from_numpy(X_train_scaled).type(torch.float32)\n",
        "y_train = torch.from_numpy(Y).type(torch.float32).unsqueeze(1)\n",
        "\n",
        "x_test = torch.from_numpy(X_test_scaled).type(torch.float32)\n",
        "y_test = torch.from_numpy(Yt).type(torch.float32).unsqueeze(1)\n",
        "\n",
        "\n",
        "input_size = x_train.shape[1]\n",
        "print(x_train.shape)\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZbQkpxkhH6G"
      },
      "source": [
        "# Define model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWDgg8yEhFMk",
        "outputId": "a08a3d6e-4fe8-4885-805f-321789ff1340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([599, 6])\n",
            "[Parameter containing:\n",
            "tensor([[ 0.2104, -0.1802, -0.0791,  0.1916, -0.3843,  0.2448]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0840], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    pred = torch.sigmoid(self.linear(x))\n",
        "    return pred\n",
        "\n",
        "  def predict(self, x):\n",
        "    pred = self.forward(x)\n",
        "    return torch.round(pred)\n",
        "\n",
        "print(x_train.shape)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "model = LogisticRegression()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08wLbfEljkE8"
      },
      "source": [
        "# function to get model parameters (w1, w2, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJX7kArljiPZ",
        "outputId": "74acca4b-484f-42e7-b882-e247c43abc0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.2104, -0.1802, -0.0791,  0.1916, -0.3843,  0.2448]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "[w, b] = model.parameters()\n",
        "print(w)\n",
        "\n",
        "w_all = w.view(-1)\n",
        "if len(features_to_use) == 1:\n",
        "  w1 = w_all[0]\n",
        "  w2 = 0\n",
        "else:\n",
        "  w1 = w_all[0]\n",
        "  w2 = w_all[1]\n",
        "\n",
        "def get_params():\n",
        "  return (w1.item(), w2.item(), b[0].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gkj4yqKlgcA"
      },
      "source": [
        "# training the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkW2eQbklixb",
        "outputId": "630ccf9c-ed03-48cb-a6ec-d60e98c9174d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:  0 loss:  0.7163392901420593\n",
            "epoch:  1 loss:  0.7008334994316101\n",
            "epoch:  2 loss:  0.6724668741226196\n",
            "epoch:  3 loss:  0.6344401240348816\n",
            "epoch:  4 loss:  0.5901374816894531\n",
            "epoch:  5 loss:  0.5427791476249695\n",
            "epoch:  6 loss:  0.4951324760913849\n",
            "epoch:  7 loss:  0.4493288993835449\n",
            "epoch:  8 loss:  0.40680763125419617\n",
            "epoch:  9 loss:  0.3683737516403198\n",
            "epoch:  10 loss:  0.33432748913764954\n",
            "epoch:  11 loss:  0.3046133518218994\n",
            "epoch:  12 loss:  0.2789560854434967\n",
            "epoch:  13 loss:  0.2569653391838074\n",
            "epoch:  14 loss:  0.23820826411247253\n",
            "epoch:  15 loss:  0.2222549319267273\n",
            "epoch:  16 loss:  0.20870423316955566\n",
            "epoch:  17 loss:  0.19719578325748444\n",
            "epoch:  18 loss:  0.18741419911384583\n",
            "epoch:  19 loss:  0.17908816039562225\n",
            "epoch:  20 loss:  0.17198677361011505\n",
            "epoch:  21 loss:  0.16591542959213257\n",
            "epoch:  22 loss:  0.16071060299873352\n",
            "epoch:  23 loss:  0.15623556077480316\n",
            "epoch:  24 loss:  0.15237608551979065\n",
            "epoch:  25 loss:  0.14903683960437775\n",
            "epoch:  26 loss:  0.14613817632198334\n",
            "epoch:  27 loss:  0.14361357688903809\n",
            "epoch:  28 loss:  0.1414073258638382\n",
            "epoch:  29 loss:  0.13947273790836334\n",
            "epoch:  30 loss:  0.1377706229686737\n",
            "epoch:  31 loss:  0.13626794517040253\n",
            "epoch:  32 loss:  0.1349368840456009\n",
            "epoch:  33 loss:  0.13375380635261536\n",
            "epoch:  34 loss:  0.13269880414009094\n",
            "epoch:  35 loss:  0.1317548304796219\n",
            "epoch:  36 loss:  0.13090747594833374\n",
            "epoch:  37 loss:  0.13014432787895203\n",
            "epoch:  38 loss:  0.1294548213481903\n",
            "epoch:  39 loss:  0.12882983684539795\n",
            "epoch:  40 loss:  0.12826159596443176\n",
            "epoch:  41 loss:  0.12774328887462616\n",
            "epoch:  42 loss:  0.12726911902427673\n",
            "epoch:  43 loss:  0.1268339902162552\n",
            "epoch:  44 loss:  0.12643349170684814\n",
            "epoch:  45 loss:  0.12606383860111237\n",
            "epoch:  46 loss:  0.12572164833545685\n",
            "epoch:  47 loss:  0.1254040002822876\n",
            "epoch:  48 loss:  0.12510834634304047\n",
            "epoch:  49 loss:  0.12483242154121399\n",
            "epoch:  50 loss:  0.12457422912120819\n",
            "epoch:  51 loss:  0.12433202564716339\n",
            "epoch:  52 loss:  0.12410429120063782\n",
            "epoch:  53 loss:  0.12388964742422104\n",
            "epoch:  54 loss:  0.12368685007095337\n",
            "epoch:  55 loss:  0.12349485605955124\n",
            "epoch:  56 loss:  0.12331269681453705\n",
            "epoch:  57 loss:  0.12313950061798096\n",
            "epoch:  58 loss:  0.12297452986240387\n",
            "epoch:  59 loss:  0.12281707674264908\n",
            "epoch:  60 loss:  0.12266653776168823\n",
            "epoch:  61 loss:  0.12252235412597656\n",
            "epoch:  62 loss:  0.12238403409719467\n",
            "epoch:  63 loss:  0.12225117534399033\n",
            "epoch:  64 loss:  0.12212332338094711\n",
            "epoch:  65 loss:  0.12200013548135757\n",
            "epoch:  66 loss:  0.12188124656677246\n",
            "epoch:  67 loss:  0.12176641076803207\n",
            "epoch:  68 loss:  0.12165535986423492\n",
            "epoch:  69 loss:  0.12154781073331833\n",
            "epoch:  70 loss:  0.12144353985786438\n",
            "epoch:  71 loss:  0.12134238332509995\n",
            "epoch:  72 loss:  0.12124413251876831\n",
            "epoch:  73 loss:  0.12114862352609634\n",
            "epoch:  74 loss:  0.12105569243431091\n",
            "epoch:  75 loss:  0.12096519768238068\n",
            "epoch:  76 loss:  0.1208769902586937\n",
            "epoch:  77 loss:  0.12079101800918579\n",
            "epoch:  78 loss:  0.12070709466934204\n",
            "epoch:  79 loss:  0.12062516063451767\n",
            "epoch:  80 loss:  0.12054509669542313\n",
            "epoch:  81 loss:  0.12046682834625244\n",
            "epoch:  82 loss:  0.12039025127887726\n",
            "epoch:  83 loss:  0.12031535804271698\n",
            "epoch:  84 loss:  0.12024199962615967\n",
            "epoch:  85 loss:  0.12017016112804413\n",
            "epoch:  86 loss:  0.1200997531414032\n",
            "epoch:  87 loss:  0.1200307309627533\n",
            "epoch:  88 loss:  0.11996304243803024\n",
            "epoch:  89 loss:  0.11989662051200867\n",
            "epoch:  90 loss:  0.11983145773410797\n",
            "epoch:  91 loss:  0.11976748704910278\n",
            "epoch:  92 loss:  0.11970464885234833\n",
            "epoch:  93 loss:  0.1196429654955864\n",
            "epoch:  94 loss:  0.11958232522010803\n",
            "epoch:  95 loss:  0.11952272802591324\n",
            "epoch:  96 loss:  0.11946414411067963\n",
            "epoch:  97 loss:  0.11940652132034302\n",
            "epoch:  98 loss:  0.11934984475374222\n",
            "epoch:  99 loss:  0.11929411441087723\n",
            "epoch:  100 loss:  0.11923928558826447\n",
            "epoch:  101 loss:  0.11918530613183975\n",
            "epoch:  102 loss:  0.1191321536898613\n",
            "epoch:  103 loss:  0.1190798431634903\n",
            "epoch:  104 loss:  0.11902833729982376\n",
            "epoch:  105 loss:  0.1189776062965393\n",
            "epoch:  106 loss:  0.11892762780189514\n",
            "epoch:  107 loss:  0.11887842416763306\n",
            "epoch:  108 loss:  0.11882989853620529\n",
            "epoch:  109 loss:  0.11878208070993423\n",
            "epoch:  110 loss:  0.11873497068881989\n",
            "epoch:  111 loss:  0.11868853867053986\n",
            "epoch:  112 loss:  0.11864271759986877\n",
            "epoch:  113 loss:  0.1185975894331932\n",
            "epoch:  114 loss:  0.1185530498623848\n",
            "epoch:  115 loss:  0.11850914359092712\n",
            "epoch:  116 loss:  0.11846582591533661\n",
            "epoch:  117 loss:  0.11842308193445206\n",
            "epoch:  118 loss:  0.11838093400001526\n",
            "epoch:  119 loss:  0.11833930760622025\n",
            "epoch:  120 loss:  0.11829826980829239\n",
            "epoch:  121 loss:  0.11825775355100632\n",
            "epoch:  122 loss:  0.11821777373552322\n",
            "epoch:  123 loss:  0.11817827820777893\n",
            "epoch:  124 loss:  0.11813931167125702\n",
            "epoch:  125 loss:  0.1181008368730545\n",
            "epoch:  126 loss:  0.11806283891201019\n",
            "epoch:  127 loss:  0.11802533268928528\n",
            "epoch:  128 loss:  0.11798829585313797\n",
            "epoch:  129 loss:  0.11795169860124588\n",
            "epoch:  130 loss:  0.11791554093360901\n",
            "epoch:  131 loss:  0.11787982285022736\n",
            "epoch:  132 loss:  0.11784455925226212\n",
            "epoch:  133 loss:  0.1178097203373909\n",
            "epoch:  134 loss:  0.11777530610561371\n",
            "epoch:  135 loss:  0.11774126440286636\n",
            "epoch:  136 loss:  0.11770763248205185\n",
            "epoch:  137 loss:  0.11767440289258957\n",
            "epoch:  138 loss:  0.11764156818389893\n",
            "epoch:  139 loss:  0.11760911345481873\n",
            "epoch:  140 loss:  0.11757703125476837\n",
            "epoch:  141 loss:  0.11754530668258667\n",
            "epoch:  142 loss:  0.11751393228769302\n",
            "epoch:  143 loss:  0.11748294532299042\n",
            "epoch:  144 loss:  0.11745228618383408\n",
            "epoch:  145 loss:  0.11742196977138519\n",
            "epoch:  146 loss:  0.11739198863506317\n",
            "epoch:  147 loss:  0.11736234277486801\n",
            "epoch:  148 loss:  0.11733303219079971\n",
            "epoch:  149 loss:  0.11730404198169708\n",
            "epoch:  150 loss:  0.11727535724639893\n",
            "epoch:  151 loss:  0.11724697798490524\n",
            "epoch:  152 loss:  0.11721893399953842\n",
            "epoch:  153 loss:  0.1171911433339119\n",
            "epoch:  154 loss:  0.11716368049383163\n",
            "epoch:  155 loss:  0.11713650077581406\n",
            "epoch:  156 loss:  0.11710960417985916\n",
            "epoch:  157 loss:  0.11708298325538635\n",
            "epoch:  158 loss:  0.11705666780471802\n",
            "epoch:  159 loss:  0.11703060567378998\n",
            "epoch:  160 loss:  0.11700481176376343\n",
            "epoch:  161 loss:  0.11697930097579956\n",
            "epoch:  162 loss:  0.11695403605699539\n",
            "epoch:  163 loss:  0.11692904680967331\n",
            "epoch:  164 loss:  0.11690426617860794\n",
            "epoch:  165 loss:  0.11687976121902466\n",
            "epoch:  166 loss:  0.11685552448034286\n",
            "epoch:  167 loss:  0.11683151870965958\n",
            "epoch:  168 loss:  0.116807721555233\n",
            "epoch:  169 loss:  0.11678420007228851\n",
            "epoch:  170 loss:  0.11676090210676193\n",
            "epoch:  171 loss:  0.11673782765865326\n",
            "epoch:  172 loss:  0.1167149767279625\n",
            "epoch:  173 loss:  0.11669235676527023\n",
            "epoch:  174 loss:  0.11666996031999588\n",
            "epoch:  175 loss:  0.11664773523807526\n",
            "epoch:  176 loss:  0.11662579327821732\n",
            "epoch:  177 loss:  0.11660400778055191\n",
            "epoch:  178 loss:  0.1165824756026268\n",
            "epoch:  179 loss:  0.11656108498573303\n",
            "epoch:  180 loss:  0.11653994768857956\n",
            "epoch:  181 loss:  0.1165190190076828\n",
            "epoch:  182 loss:  0.11649825423955917\n",
            "epoch:  183 loss:  0.11647769808769226\n",
            "epoch:  184 loss:  0.11645733565092087\n",
            "epoch:  185 loss:  0.1164371445775032\n",
            "epoch:  186 loss:  0.11641713231801987\n",
            "epoch:  187 loss:  0.11639732867479324\n",
            "epoch:  188 loss:  0.11637771129608154\n",
            "epoch:  189 loss:  0.11635826528072357\n",
            "epoch:  190 loss:  0.11633899062871933\n",
            "epoch:  191 loss:  0.1163199171423912\n",
            "epoch:  192 loss:  0.11630097776651382\n",
            "epoch:  193 loss:  0.11628222465515137\n",
            "epoch:  194 loss:  0.11626364290714264\n",
            "epoch:  195 loss:  0.11624522507190704\n",
            "epoch:  196 loss:  0.11622697114944458\n",
            "epoch:  197 loss:  0.11620885878801346\n",
            "epoch:  198 loss:  0.11619094014167786\n",
            "epoch:  199 loss:  0.1161731630563736\n",
            "epoch:  200 loss:  0.11615554243326187\n",
            "epoch:  201 loss:  0.11613808572292328\n",
            "epoch:  202 loss:  0.11612077057361603\n",
            "epoch:  203 loss:  0.11610361933708191\n",
            "epoch:  204 loss:  0.11608660221099854\n",
            "epoch:  205 loss:  0.1160697340965271\n",
            "epoch:  206 loss:  0.1160530224442482\n",
            "epoch:  207 loss:  0.11603644490242004\n",
            "epoch:  208 loss:  0.11601998656988144\n",
            "epoch:  209 loss:  0.11600370705127716\n",
            "epoch:  210 loss:  0.11598756164312363\n",
            "epoch:  211 loss:  0.11597155034542084\n",
            "epoch:  212 loss:  0.11595563590526581\n",
            "epoch:  213 loss:  0.1159399002790451\n",
            "epoch:  214 loss:  0.11592428386211395\n",
            "epoch:  215 loss:  0.11590880900621414\n",
            "epoch:  216 loss:  0.11589346081018448\n",
            "epoch:  217 loss:  0.11587822437286377\n",
            "epoch:  218 loss:  0.11586310714483261\n",
            "epoch:  219 loss:  0.11584813892841339\n",
            "epoch:  220 loss:  0.11583326011896133\n",
            "epoch:  221 loss:  0.11581851541996002\n",
            "epoch:  222 loss:  0.11580391973257065\n",
            "epoch:  223 loss:  0.11578941345214844\n",
            "epoch:  224 loss:  0.11577505618333817\n",
            "epoch:  225 loss:  0.11576078087091446\n",
            "epoch:  226 loss:  0.11574665457010269\n",
            "epoch:  227 loss:  0.1157326027750969\n",
            "epoch:  228 loss:  0.11571867018938065\n",
            "epoch:  229 loss:  0.11570488661527634\n",
            "epoch:  230 loss:  0.11569119244813919\n",
            "epoch:  231 loss:  0.1156776174902916\n",
            "epoch:  232 loss:  0.11566411703824997\n",
            "epoch:  233 loss:  0.11565074324607849\n",
            "epoch:  234 loss:  0.11563747376203537\n",
            "epoch:  235 loss:  0.1156243160367012\n",
            "epoch:  236 loss:  0.11561126261949539\n",
            "epoch:  237 loss:  0.11559830605983734\n",
            "epoch:  238 loss:  0.11558543890714645\n",
            "epoch:  239 loss:  0.11557270586490631\n",
            "epoch:  240 loss:  0.11556005477905273\n",
            "epoch:  241 loss:  0.11554748564958572\n",
            "epoch:  242 loss:  0.11553502827882767\n",
            "epoch:  243 loss:  0.11552264541387558\n",
            "epoch:  244 loss:  0.11551038175821304\n",
            "epoch:  245 loss:  0.11549819260835648\n",
            "epoch:  246 loss:  0.11548610776662827\n",
            "epoch:  247 loss:  0.11547413468360901\n",
            "epoch:  248 loss:  0.11546219885349274\n",
            "epoch:  249 loss:  0.11545044183731079\n",
            "epoch:  250 loss:  0.11543868482112885\n",
            "epoch:  251 loss:  0.11542706936597824\n",
            "epoch:  252 loss:  0.11541552096605301\n",
            "epoch:  253 loss:  0.11540405452251434\n",
            "epoch:  254 loss:  0.11539270728826523\n",
            "epoch:  255 loss:  0.11538141220808029\n",
            "epoch:  256 loss:  0.11537019163370132\n",
            "epoch:  257 loss:  0.1153590977191925\n",
            "epoch:  258 loss:  0.11534804850816727\n",
            "epoch:  259 loss:  0.11533711105585098\n",
            "epoch:  260 loss:  0.11532621830701828\n",
            "epoch:  261 loss:  0.11531542986631393\n",
            "epoch:  262 loss:  0.11530470848083496\n",
            "epoch:  263 loss:  0.11529407650232315\n",
            "epoch:  264 loss:  0.1152835264801979\n",
            "epoch:  265 loss:  0.11527300626039505\n",
            "epoch:  266 loss:  0.11526266485452652\n",
            "epoch:  267 loss:  0.1152522936463356\n",
            "epoch:  268 loss:  0.11524204164743423\n",
            "epoch:  269 loss:  0.11523185670375824\n",
            "epoch:  270 loss:  0.11522173881530762\n",
            "epoch:  271 loss:  0.11521171778440475\n",
            "epoch:  272 loss:  0.11520175635814667\n",
            "epoch:  273 loss:  0.11519184708595276\n",
            "epoch:  274 loss:  0.11518202722072601\n",
            "epoch:  275 loss:  0.11517226696014404\n",
            "epoch:  276 loss:  0.11516258865594864\n",
            "epoch:  277 loss:  0.11515296995639801\n",
            "epoch:  278 loss:  0.11514343321323395\n",
            "epoch:  279 loss:  0.11513393372297287\n",
            "epoch:  280 loss:  0.11512454599142075\n",
            "epoch:  281 loss:  0.1151151955127716\n",
            "epoch:  282 loss:  0.11510591208934784\n",
            "epoch:  283 loss:  0.11509670317173004\n",
            "epoch:  284 loss:  0.11508751660585403\n",
            "epoch:  285 loss:  0.11507843434810638\n",
            "epoch:  286 loss:  0.11506940424442291\n",
            "epoch:  287 loss:  0.11506044119596481\n",
            "epoch:  288 loss:  0.11505155265331268\n",
            "epoch:  289 loss:  0.11504267156124115\n",
            "epoch:  290 loss:  0.11503392457962036\n",
            "epoch:  291 loss:  0.11502519994974136\n",
            "epoch:  292 loss:  0.11501653492450714\n",
            "epoch:  293 loss:  0.1150079146027565\n",
            "epoch:  294 loss:  0.11499939113855362\n",
            "epoch:  295 loss:  0.11499091982841492\n",
            "epoch:  296 loss:  0.11498244851827621\n",
            "epoch:  297 loss:  0.11497408151626587\n",
            "epoch:  298 loss:  0.1149657666683197\n",
            "epoch:  299 loss:  0.11495751142501831\n",
            "epoch:  300 loss:  0.11494932323694229\n",
            "epoch:  301 loss:  0.11494114995002747\n",
            "epoch:  302 loss:  0.1149330735206604\n",
            "epoch:  303 loss:  0.11492501944303513\n",
            "epoch:  304 loss:  0.11491702497005463\n",
            "epoch:  305 loss:  0.1149090901017189\n",
            "epoch:  306 loss:  0.11490121483802795\n",
            "epoch:  307 loss:  0.1148933693766594\n",
            "epoch:  308 loss:  0.1148855984210968\n",
            "epoch:  309 loss:  0.1148778572678566\n",
            "epoch:  310 loss:  0.11487021297216415\n",
            "epoch:  311 loss:  0.11486256122589111\n",
            "epoch:  312 loss:  0.11485498398542404\n",
            "epoch:  313 loss:  0.11484745144844055\n",
            "epoch:  314 loss:  0.11483996361494064\n",
            "epoch:  315 loss:  0.11483252793550491\n",
            "epoch:  316 loss:  0.11482516676187515\n",
            "epoch:  317 loss:  0.11481781303882599\n",
            "epoch:  318 loss:  0.1148105263710022\n",
            "epoch:  319 loss:  0.11480328440666199\n",
            "epoch:  320 loss:  0.11479607224464417\n",
            "epoch:  321 loss:  0.11478894203901291\n",
            "epoch:  322 loss:  0.11478184908628464\n",
            "epoch:  323 loss:  0.11477474868297577\n",
            "epoch:  324 loss:  0.11476773023605347\n",
            "epoch:  325 loss:  0.11476077884435654\n",
            "epoch:  326 loss:  0.1147538498044014\n",
            "epoch:  327 loss:  0.11474697291851044\n",
            "epoch:  328 loss:  0.11474013328552246\n",
            "epoch:  329 loss:  0.11473331600427628\n",
            "epoch:  330 loss:  0.11472655832767487\n",
            "epoch:  331 loss:  0.11471986770629883\n",
            "epoch:  332 loss:  0.11471320688724518\n",
            "epoch:  333 loss:  0.11470656841993332\n",
            "epoch:  334 loss:  0.11469998955726624\n",
            "epoch:  335 loss:  0.11469344049692154\n",
            "epoch:  336 loss:  0.11468692123889923\n",
            "epoch:  337 loss:  0.11468042433261871\n",
            "epoch:  338 loss:  0.11467403173446655\n",
            "epoch:  339 loss:  0.114667609333992\n",
            "epoch:  340 loss:  0.11466129124164581\n",
            "epoch:  341 loss:  0.11465495079755783\n",
            "epoch:  342 loss:  0.1146487221121788\n",
            "epoch:  343 loss:  0.11464247852563858\n",
            "epoch:  344 loss:  0.11463626474142075\n",
            "epoch:  345 loss:  0.11463009566068649\n",
            "epoch:  346 loss:  0.11462397128343582\n",
            "epoch:  347 loss:  0.11461786925792694\n",
            "epoch:  348 loss:  0.11461183428764343\n",
            "epoch:  349 loss:  0.11460580676794052\n",
            "epoch:  350 loss:  0.11459986120462418\n",
            "epoch:  351 loss:  0.11459388583898544\n",
            "epoch:  352 loss:  0.11458799988031387\n",
            "epoch:  353 loss:  0.1145821213722229\n",
            "epoch:  354 loss:  0.1145762950181961\n",
            "epoch:  355 loss:  0.11457047611474991\n",
            "epoch:  356 loss:  0.1145646944642067\n",
            "epoch:  357 loss:  0.11455898731946945\n",
            "epoch:  358 loss:  0.1145532950758934\n",
            "epoch:  359 loss:  0.11454758793115616\n",
            "epoch:  360 loss:  0.11454199999570847\n",
            "epoch:  361 loss:  0.114536352455616\n",
            "epoch:  362 loss:  0.11453080177307129\n",
            "epoch:  363 loss:  0.11452525854110718\n",
            "epoch:  364 loss:  0.11451977491378784\n",
            "epoch:  365 loss:  0.1145142987370491\n",
            "epoch:  366 loss:  0.11450884491205215\n",
            "epoch:  367 loss:  0.11450342833995819\n",
            "epoch:  368 loss:  0.11449804157018661\n",
            "epoch:  369 loss:  0.11449269205331802\n",
            "epoch:  370 loss:  0.11448737978935242\n",
            "epoch:  371 loss:  0.114482082426548\n",
            "epoch:  372 loss:  0.11447680741548538\n",
            "epoch:  373 loss:  0.11447159945964813\n",
            "epoch:  374 loss:  0.11446641385555267\n",
            "epoch:  375 loss:  0.11446124315261841\n",
            "epoch:  376 loss:  0.11445608735084534\n",
            "epoch:  377 loss:  0.11445098370313644\n",
            "epoch:  378 loss:  0.11444588750600815\n",
            "epoch:  379 loss:  0.11444082856178284\n",
            "epoch:  380 loss:  0.11443578451871872\n",
            "epoch:  381 loss:  0.11443079262971878\n",
            "epoch:  382 loss:  0.11442580074071884\n",
            "epoch:  383 loss:  0.11442086845636368\n",
            "epoch:  384 loss:  0.1144159659743309\n",
            "epoch:  385 loss:  0.11441107839345932\n",
            "epoch:  386 loss:  0.11440622061491013\n",
            "epoch:  387 loss:  0.11440138518810272\n",
            "epoch:  388 loss:  0.11439656466245651\n",
            "epoch:  389 loss:  0.11439178138971329\n",
            "epoch:  390 loss:  0.11438699066638947\n",
            "epoch:  391 loss:  0.11438227444887161\n",
            "epoch:  392 loss:  0.11437755078077316\n",
            "epoch:  393 loss:  0.11437290161848068\n",
            "epoch:  394 loss:  0.11436823010444641\n",
            "epoch:  395 loss:  0.11436358094215393\n",
            "epoch:  396 loss:  0.11435896903276443\n",
            "epoch:  397 loss:  0.11435442417860031\n",
            "epoch:  398 loss:  0.1143498346209526\n",
            "epoch:  399 loss:  0.11434531211853027\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.9)\n",
        "\n",
        "# training the model \n",
        "epochs = 400\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  y_pred = model.forward(x_train)\n",
        "\n",
        "\n",
        "  loss = criterion(y_pred, y_train)\n",
        "\n",
        "  # regularizer\n",
        "  # l1_lambda = 0.035\n",
        "  # l2_lambda = 0.051\n",
        "\n",
        "  #test value - without regularization\n",
        "  # l1_lambda = 0\n",
        "  # l2_lambda = 0\n",
        "\n",
        "  first_param = next(model.parameters())\n",
        "  l1_reg = first_param.new_tensor(0.)\n",
        "  l2_reg = first_param.new_tensor(0.)\n",
        "  for param in model.parameters():\n",
        "      l1_reg.add_(torch.norm(param, 1))\n",
        "      l2_reg.add_(torch.norm(param, 2))\n",
        "      loss += l1_lambda * l1_reg + l2_lambda * l2_reg\n",
        "\n",
        "  print(\"epoch: \", i, \"loss: \", loss.item())\n",
        "  losses.append(loss.item())\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "rYkUBuB2lfiU",
        "outputId": "63fd9966-cd89-4766-e515-ccc7f031fa95"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# log loss\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80NQ8m48n8fM"
      },
      "source": [
        "# model evalation with new datasets the model has never seen before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy_train= 95.4924874791%\n",
            "accuracy_test= 100.0000000000%\n"
          ]
        }
      ],
      "source": [
        "#  \n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_train = model.predict(x_train)\n",
        "\n",
        "no_correct_train = y_pred_train.eq(y_train).sum().item()\n",
        "\n",
        "accuracy_train = no_correct_train / len(x_train) * 100\n",
        "print(f\"accuracy_train= {accuracy_train:.10f}%\")\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred_test = model.predict(x_test)\n",
        "\n",
        "no_correct_test = y_pred_test.eq(y_test).sum().item()\n",
        "\n",
        "accuracy_test = no_correct_test / len(x_test) * 100\n",
        "print(f\"accuracy_test= {accuracy_test:.10f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment1_starter_edited.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
